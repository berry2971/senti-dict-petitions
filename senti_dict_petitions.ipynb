{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "senti-dict-petitions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/berry2971/senti-dict-petitions/blob/master/senti_dict_petitions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73-M4alHe5bR",
        "colab_type": "text"
      },
      "source": [
        "###과제 의의\n",
        "* '불만'이라는 특정한 감성을 추출해내기란 쉽지 않다. 하지만 국민청원 게시판은 '불만, 원망, 간청'이라는 감성이 전적으로 드러나 있는 게시판이다. 이에 국민청원 게시판의 텍스트 분석을 통해 '불만'의 감성을 가진 단어들을 상당히 추출할 수 있을 것으로 보인다.\n",
        "\n",
        "###과제 수행 방법\n",
        "#####스크래핑\n",
        "Selenium을 사용하되, 별도의 코드로 실행함. (https://github.com/berry2971/scraper-petitions)\n",
        "\n",
        "#####분석 대상\n",
        "* 130641건의 국민청원을 대상으로 함.\n",
        "* 보건복지:\t6317\n",
        "* 저출산/고령화대책:\t960\n",
        "* 행정:\t6673\n",
        "* 미래:\t7589\n",
        "* 안전/환경:\t11460\n",
        "* 성장동력:\t3506\n",
        "* 기타:\t16800\n",
        "* 일자리:\t6884\n",
        "* 외교/통일/국방:\t9385\n",
        "* 반려동물:\t1481\n",
        "* 교통/건축/국토:\t8603\n",
        "* 경제민주화:\t6591\n",
        "* 농산어촌:\t603\n",
        "* 육아/교육:\t6833\n",
        "*  정치개혁:\t19518\n",
        "* 인권/성평등:\t10177\n",
        "* 문화/예술/체육/언론:\t7261\n",
        "\n",
        "####형태소 분석\n",
        "* 형태소 분석의 경우, SentencePiece 등 비지도 기반 형태소 분석기를 사용할 수도 있지만, 국민청원의 경우 꽤나 정제된 언어로 작성될 뿐만 아니라 욕설 등 연구 가치가 있지만 OOV가 발생할 가능성이 높은 어휘들은 대부분 게시판 관리자에 의해 제거된다. 따라서 Mecab을 사용하였다.\n",
        "\n",
        "####KNU(케이앤유) 한국어 감성 사전(군산대학교) 사용\n",
        "* https://github.com/park1200656/KnuSentiLex\n",
        "* 박상민(군산대학교)·나철원(군산대학교)·최민성(군산대학교)·이다희(군산대학교)· 온병원(군산대학교)(2018), Bi-LSTM 기반의 한국어 감성사전 구축 방안\n",
        "* KNU 한국어 감성 사전은 형용사뿐만 아니라 부사 등을 포함하고 있어 보다 풍부한 어휘를 지니고 있고, 도메인에서 비교적 자유롭다. 14843개의 어휘로 구성되어 있다.\n",
        "* 기발표된 KNU 한국어 감성 사전의 부정 극성 단어를 기반으로 하여, 해당 단어와 유사한 맥락을 지니는 단어들을 국민청원 게시물에서 Word2Vec을 통해 형용사(VA)/부사(MAG)/동사(VV)를 추출해 낸다.\n",
        "* NNG, NNP의 경우 감성이 아닌 해당 시기의 이슈와 트렌드를 반영하여 분석될 확률이 다분하여 추출 대상에서 제외한다.\n",
        "* KNU 한국어 감성 사전의 각 단어들에 대해 추출이 진행되기 때문에 중복되는 단어가 발생하는데, 이 경우 가장 높은 코사인 유사도를 단어와 함께 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIXXIX-9oGk8",
        "colab_type": "code",
        "outputId": "d98a5319-5d88-4161-de51-a9fcabb8f994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "##### Mount Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPlcVGazopN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Connect with db (raw text)\n",
        "import sqlite3\n",
        "con1 = sqlite3.connect('/content/gdrive/My Drive/senti/result_petitions.db')\n",
        "cur1 = con1.cursor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV5ojN0Sovuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Connect with db (analyzed text)\n",
        "con2 = sqlite3.connect('/content/gdrive/My Drive/senti/result_petitions_tagged.db')\n",
        "\n",
        "##### EXECUTE FIRST TIME ONLY\n",
        "#con2.execute('CREATE TABLE analysis (TAGGED BLOB, CATEGORY TEXT, AGREES INTEGER)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJhr9Ugfo06B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########## EXECUTE FIRST TIME ONLY ##########\n",
        "##### Prepare pos tagger: mecab\n",
        "!pip install -v python-mecab-ko\n",
        "import mecab\n",
        "mecab = mecab.MeCab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcKKB8QGo1Rc",
        "colab_type": "code",
        "outputId": "6a6c0d5f-20c1-463d-9735-251ca190f5b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "########## EXECUTE FIRST TIME ONLY ##########\n",
        "##### Prepare sentence divider: kss(Korean Sentence Splitter by 박상길)\n",
        "!pip install kss\n",
        "import kss\n",
        "\n",
        "'''\n",
        "raw = \"안녕하세요. 오늘은 날씨가 맑네요! 하늘도 푸르구요! 미세먼지만 없으면ㅠㅠ 좋을텐데ㅠㅠ\"\n",
        "kss.split_sentences(raw)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kss in /usr/local/lib/python3.6/dist-packages (1.2.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nraw = \"안녕하세요. 오늘은 날씨가 맑네요! 하늘도 푸르구요! 미세먼지만 없으면ㅠㅠ 좋을텐데ㅠㅠ\"\\nkss.split_sentences(raw)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdS9plDMo3E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########## SPENDS LONG TIME ##########\n",
        "########## EXECUTE FIRST TIME ONLY ##########\n",
        "##### Pos tag and save it into database\n",
        "import pickle\n",
        "\n",
        "count = 0\n",
        "for row in cur1.execute(\"SELECT title, content, category, agrees FROM petitions\"):\n",
        "    # Insert pickled data into database\n",
        "    tagged_sentences = [mecab.pos(sentence) for sentence in kss.split_sentences(row[0]+\" \"+row[1])] # data\n",
        "    data = tagged_sentences\n",
        "    pdata = pickle.dumps(data)\n",
        "    con2.execute('INSERT INTO analysis (TAGGED, CATEGORY, AGREES) VALUES (?, ?, ?)', [pdata, row[2], row[3]])\n",
        "  \n",
        "    # Check progress and Commit database\n",
        "    count += 1\n",
        "    if count % 1000 == 0:\n",
        "        print(count)\n",
        "        con2.commit()\n",
        "\n",
        "con2.commit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnL6gjmwm4Q1",
        "colab_type": "text"
      },
      "source": [
        "categories:\n",
        "\n",
        "{'보건복지', '저출산/고령화대책', '행정', '미래', '안전/환경', '성장동력', '기타', '일자리', '외교/통일/국방', '반려동물', '교통/건축/국토', '경제민주화', '농산어촌', '육아/교육', '정치개혁', '인권/성평등', '문화/예술/체육/언론'}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ylx1TwcdqqXH",
        "colab_type": "code",
        "outputId": "d2099d1f-b91e-4ad1-cb30-ecda88d98d20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "# Load database\n",
        "import pickle\n",
        "\n",
        "con3 = con2\n",
        "cur3 = con3.cursor()\n",
        "\n",
        "data_ctg = dict()\n",
        "categories = ['보건복지', '저출산/고령화대책', '행정', '미래', '안전/환경', '성장동력', '기타', '일자리', '외교/통일/국방', '반려동물', '교통/건축/국토', '경제민주화', '농산어촌', '육아/교육', '정치개혁', '인권/성평등', '문화/예술/체육/언론']\n",
        "count_doc_categories = []\n",
        "for i in range(len(categories)):\n",
        "    count_doc_categories.append(0)\n",
        "for c in categories:\n",
        "    data_ctg.update({c:[]})\n",
        "\n",
        "count = 0\n",
        "for docs in cur3.execute(\"SELECT * FROM analysis\"):\n",
        "    # Check progress\n",
        "    count += 1\n",
        "    if count % 15000 == 0:\n",
        "        print(count, end='...')\n",
        "        print(int(count/130641*100), end='')\n",
        "        print(\"%\")\n",
        "    if count == 130641:\n",
        "        print(\"130641...100%\")\n",
        "\n",
        "    content = pickle.loads(docs[0])\n",
        "    category = docs[1]\n",
        "    agrees = docs[2]\n",
        "\n",
        "    # Count numbers\n",
        "    count_doc_categories[categories.index(category)] += 1\n",
        "\n",
        "    # Convert (안녕, IC) to 안녕/IC\n",
        "    for sentence in content:\n",
        "        for i in range(len(sentence)):\n",
        "            word = sentence[i][0]\n",
        "            pos = sentence[i][1]\n",
        "            tagged_word = word+\"/\"+pos\n",
        "            sentence[i] = tagged_word\n",
        "\n",
        "    data_ctg[category].append((content, agrees))\n",
        "\n",
        "for c in categories:\n",
        "    print(\"{c}:\\t{num}\".format(c=c, num=count_doc_categories[categories.index(c)]))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15000...11%\n",
            "30000...22%\n",
            "45000...34%\n",
            "60000...45%\n",
            "75000...57%\n",
            "90000...68%\n",
            "105000...80%\n",
            "120000...91%\n",
            "130641...100%\n",
            "보건복지:\t6317\n",
            "저출산/고령화대책:\t960\n",
            "행정:\t6673\n",
            "미래:\t7589\n",
            "안전/환경:\t11460\n",
            "성장동력:\t3506\n",
            "기타:\t16800\n",
            "일자리:\t6884\n",
            "외교/통일/국방:\t9385\n",
            "반려동물:\t1481\n",
            "교통/건축/국토:\t8603\n",
            "경제민주화:\t6591\n",
            "농산어촌:\t603\n",
            "육아/교육:\t6833\n",
            "정치개혁:\t19518\n",
            "인권/성평등:\t10177\n",
            "문화/예술/체육/언론:\t7261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jARm60nyimw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Preprocess data\n",
        "data_ctg_sentences = dict() # {'보건복지':[['먼저/MAG','가/VV', '아/EF'], ['오늘/NNG', '도/JX']], '일자리':[['성공/NNG', '하/XSV', '았/EP', '나/EF'], ['글쎄/IC']], ...}\n",
        "categories = ['보건복지', '저출산/고령화대책', '행정', '미래', '안전/환경', '성장동력', '기타', '일자리', '외교/통일/국방', '반려동물', '교통/건축/국토', '경제민주화', '농산어촌', '육아/교육', '정치개혁', '인권/성평등', '문화/예술/체육/언론']\n",
        "for c in categories:\n",
        "    data_ctg_sentences.update({c:[]})\n",
        "\n",
        "for key in data_ctg.keys():\n",
        "    sentences = []\n",
        "    for d in data_ctg[key]:\n",
        "        for sentence in d[0]:\n",
        "            sentences.append(sentence)\n",
        "    data_ctg_sentences[key].extend(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "devHZHK7zffV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "models = []\n",
        "\n",
        "count = 0\n",
        "for v in data_ctg_sentences.values():\n",
        "    count += 1\n",
        "    print(\"{cntt}/17\".format(cntt=count))\n",
        "    models.append(Word2Vec(v, size=300, window=3, min_count=10, workers=4, sg=1, iter=50, sample=0.00001))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jn21Z1UE9bR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_token(token):\n",
        "    word = re.search(\"(.*)/(.*)\", token).group(1)\n",
        "    pos = re.search(\"(.*)/(.*)\", token).group(2)\n",
        "    return (word, pos)\n",
        "\n",
        "def parse_tagged_word(word):\n",
        "    lst = word.split(sep = \"/\")\n",
        "    return (lst[0], lst[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLdqc96FxIgq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "ae21a06c-ae6a-4075-8589-82eec4b8f77e"
      },
      "source": [
        "##### t-SNE: t-Stochastic Neighbor Embedding\n",
        "import re\n",
        "import matplotlib\n",
        "import matplotlib.font_manager as fm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "obj_model = models[0]\n",
        "\n",
        "mag_list = [w for w in list(obj_model.wv.vocab) if parse_token(w)[1]=='MAG']\n",
        "\n",
        "\n",
        "\n",
        "matplotlib.rcParams[\"axes.unicode_minus\"] = False\n",
        "\n",
        "#vocab = obj_model.wv.vocab\n",
        "vocab = mag_list\n",
        "X = obj_model[vocab]\n",
        "\n",
        "tsne = TSNE(n_components = 2)\n",
        "X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "##### Show data frame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(X_tsne, index = vocab, columns = [\"x\", \"y\"])\n",
        "df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>워낙/MAG</th>\n",
              "      <td>4.992065</td>\n",
              "      <td>2.061124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>제대로/MAG</th>\n",
              "      <td>1.679194</td>\n",
              "      <td>2.639233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>안/MAG</th>\n",
              "      <td>0.790547</td>\n",
              "      <td>1.923129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>함께/MAG</th>\n",
              "      <td>2.235300</td>\n",
              "      <td>9.134355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>벌써/MAG</th>\n",
              "      <td>-4.085002</td>\n",
              "      <td>9.280380</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                x         y\n",
              "워낙/MAG   4.992065  2.061124\n",
              "제대로/MAG  1.679194  2.639233\n",
              "안/MAG    0.790547  1.923129\n",
              "함께/MAG   2.235300  9.134355\n",
              "벌써/MAG  -4.085002  9.280380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUqrOoXqBe-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Install Nanum Fonts\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum* -qq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_WntRZtFWhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Draw figure\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.set_size_inches(30,20)\n",
        "\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.scatter(df[\"x\"], df[\"y\"])\n",
        "\n",
        "prop = fm.FontProperties(fname = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\")\n",
        "for word, pos in list(df.iterrows()):\n",
        "  ax.annotate(word, pos, fontsize = 12, fontproperties = prop)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8iM-_rsHFcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Read KNU neg_pol_word\n",
        "knu_negv_words = set()\n",
        "with open('/content/gdrive/My Drive/senti/neg_pol_word.txt', 'r', encoding = 'utf8') as f:\n",
        "    knu_negv_file = f.readlines()\n",
        "\n",
        "one_ej = 0\n",
        "for i in range(len(knu_negv_file)):\n",
        "    item = knu_negv_file[i]\n",
        "    knu_negv_file[i] = item.strip()\n",
        "    item = knu_negv_file[i]\n",
        "    if (len(item.split(sep=' ')) == 1): # apply for single ej item only\n",
        "        one_ej += 1\n",
        "        pos_res = mecab.pos(item)\n",
        "        tagged_item = pos_res[0][0]+\"/\"+pos_res[0][1]\n",
        "        knu_negv_words.add(tagged_item)\n",
        "knu_negv_words = list(knu_negv_words) # ['방탕/NNG', '^-^;;/SY', '결핍/NNG', '짖궂/VA', '맛없/VA']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a98VrfYUHOwb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "f3af2029-024a-48ae-b3bd-f027b7a35f4e"
      },
      "source": [
        "##### Get word set\n",
        "for i in range(len(models)):\n",
        "    print(\"model_{name}\".format(name=categories[i]))\n",
        "    cur_model = models[i]\n",
        "    cur_negv_words = []\n",
        "    for word in knu_negv_words:\n",
        "        try:\n",
        "            cur_sims = cur_model.wv.most_similar(word, topn = 10)\n",
        "            for w in cur_sims:\n",
        "                if parse_tagged_word(w[0])[1] in ['MAG','VA','VV']:\n",
        "                    cur_negv_words.append(w)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    wordset = set()\n",
        "    for w in cur_negv_words:\n",
        "        wordset.add(w[0])\n",
        "    \n",
        "    worddict = dict()\n",
        "    for w in wordset:\n",
        "        worddict[w] = []\n",
        "    \n",
        "    for w in cur_negv_words:\n",
        "        worddict[w[0]].append(w[1])\n",
        "    \n",
        "    for key in worddict.keys():\n",
        "        worddict[key] = max(worddict[key])\n",
        "    \n",
        "    print(list(worddict.items())[:10])\n",
        "    print(len(list(worddict.items())))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model_보건복지\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[('월등히/MAG', 0.5061543583869934), ('외치/VV', 0.3822783827781677), ('되묻/VV', 0.5748921632766724), ('쳐다보/VV', 0.5293914079666138), ('흘러가/VV', 0.5267065167427063), ('지금/MAG', 0.3621225655078888), ('말리/VV', 0.5711488723754883), ('점점점/MAG', 0.7370374202728271), ('붙잡/VV', 0.4601231515407562), ('급히/MAG', 0.37684696912765503)]\n",
            "439\n",
            "model_저출산/고령화대책\n",
            "[('월등히/MAG', 0.944807767868042), ('맨날/MAG', 0.9918994307518005), ('나누/VV', 0.976642370223999), ('매번/MAG', 0.9933590292930603), ('간절히/MAG', 0.9853604435920715), ('좀/MAG', 0.9791259765625), ('심지어/MAG', 0.9619573354721069), ('잘/MAG', 0.9791260957717896), ('누리/VV', 0.9830825328826904), ('갑자기/MAG', 0.9862367510795593)]\n",
            "219\n",
            "model_행정\n",
            "[('어짜피/MAG', 0.49736422300338745), ('되묻/VV', 0.35155895352363586), ('추/VV', 0.3514246940612793), ('차/VA', 0.5480322241783142), ('붙잡/VV', 0.4528171718120575), ('손놓/VV', 0.49715811014175415), ('모조리/MAG', 0.47510021924972534), ('싸/VV', 0.44332456588745117), ('너무/MAG', 0.4117417335510254), ('몰려들/VV', 0.5648715496063232)]\n",
            "398\n",
            "model_미래\n",
            "[('천천히/MAG', 0.34587404131889343), ('돌려보내/VV', 0.4514044523239136), ('지금/MAG', 0.3741248846054077), ('붙잡/VV', 0.5052587389945984), ('줄어드/VV', 0.43236905336380005), ('영원히/MAG', 0.3543277382850647), ('통/MAG', 0.43741917610168457), ('싸/VV', 0.477502703666687), ('풀리/VV', 0.4551418423652649), ('빨아먹/VV', 0.586552083492279)]\n",
            "411\n",
            "model_안전/환경\n",
            "[('각자/MAG', 0.3581666350364685), ('울부짖/VV', 0.5891815423965454), ('말리/VV', 0.4326041042804718), ('맘껏/MAG', 0.46623873710632324), ('급히/MAG', 0.34610217809677124), ('및/VV', 0.38263487815856934), ('손놓/VV', 0.40302765369415283), ('고의로/MAG', 0.3260180354118347), ('그라/VV', 0.44622910022735596), ('빨아먹/VV', 0.3979864716529846)]\n",
            "466\n",
            "model_성장동력\n",
            "[('바르/VV', 0.7262926697731018), ('행하/VV', 0.8011281490325928), ('너무나/MAG', 0.7745777368545532), ('쳐다보/VV', 0.7905495166778564), ('갚/VV', 0.8536038398742676), ('좀/MAG', 0.7098898887634277), ('매번/MAG', 0.5766224265098572), ('시달리/VV', 0.8091821670532227), ('옥죄/VV', 0.7665332555770874), ('팔리/VV', 0.6914048194885254)]\n",
            "301\n",
            "model_기타\n",
            "[('월등히/MAG', 0.40771034359931946), ('쳐다보/VV', 0.4111655354499817), ('아직/MAG', 0.3792021870613098), ('지금/MAG', 0.3976461589336395), ('거슬리/VV', 0.4623449444770813), ('고의로/MAG', 0.29420292377471924), ('너무/MAG', 0.46361494064331055), ('면밀히/MAG', 0.3202804923057556), ('그라/VV', 0.4634442925453186), ('말미암/VV', 0.3723317086696625)]\n",
            "531\n",
            "model_일자리\n",
            "[('각자/MAG', 0.4761354923248291), ('쳐다보/VV', 0.47931039333343506), ('흘러가/VV', 0.42247867584228516), ('지금/MAG', 0.4073093831539154), ('말리/VV', 0.4900118112564087), ('차/VA', 0.476432740688324), ('붙잡/VV', 0.42934656143188477), ('모조리/MAG', 0.37030500173568726), ('서글프/VA', 0.6094422340393066), ('줄어드/VV', 0.5179307460784912)]\n",
            "384\n",
            "model_외교/통일/국방\n",
            "[('각자/MAG', 0.4374105632305145), ('어짜피/MAG', 0.4610075354576111), ('천천히/MAG', 0.4521898329257965), ('돌려받/VV', 0.5004012584686279), ('되묻/VV', 0.5556905269622803), ('쳐다보/VV', 0.380401074886322), ('옥죄/VV', 0.4248267710208893), ('지금/MAG', 0.3963475823402405), ('붙잡/VV', 0.37661677598953247), ('급히/MAG', 0.394987016916275)]\n",
            "460\n",
            "model_반려동물\n",
            "[('고작/MAG', 0.9316478967666626), ('분명히/MAG', 0.9878600239753723), ('너무나/MAG', 0.9940834641456604), ('실제로/MAG', 0.9786816239356995), ('좀/MAG', 0.9698492288589478), ('싸우/VV', 0.9944467544555664), ('심지어/MAG', 0.9936355352401733), ('만지/VV', 0.9941918849945068), ('누리/VV', 0.9924247860908508), ('갑자기/MAG', 0.9874866008758545)]\n",
            "308\n",
            "model_교통/건축/국토\n",
            "[('울부짖/VV', 0.388539582490921), ('챙/MAG', 0.3844277858734131), ('흘러가/VV', 0.4657493829727173), ('지금/MAG', 0.35538098216056824), ('말리/VV', 0.47321271896362305), ('붙잡/VV', 0.4237894117832184), ('손놓/VV', 0.4672790765762329), ('급히/MAG', 0.34892159700393677), ('줄어드/VV', 0.4085945188999176), ('둘러보/VV', 0.48944562673568726)]\n",
            "398\n",
            "model_경제민주화\n",
            "[('각자/MAG', 0.3906855583190918), ('천천히/MAG', 0.4971238970756531), ('쳐다보/VV', 0.4320971667766571), ('흘러가/VV', 0.5392425060272217), ('옥죄/VV', 0.552035391330719), ('거듭/MAG', 0.3605670630931854), ('거슬리/VV', 0.6704565286636353), ('모조리/MAG', 0.39512133598327637), ('뚫/VV', 0.5006752610206604), ('줄어드/VV', 0.43359842896461487)]\n",
            "384\n",
            "model_농산어촌\n",
            "[('농사지/VV', 0.9990085959434509), ('갚/VV', 0.9973452091217041), ('너무나/MAG', 0.9989808797836304), ('완전히/MAG', 0.9938948154449463), ('좀/MAG', 0.9988007545471191), ('싸우/VV', 0.9986023306846619), ('심지어/MAG', 0.9992409944534302), ('잡/VV', 0.9974621534347534), ('잘/MAG', 0.9988007545471191), ('누리/VV', 0.997018575668335)]\n",
            "168\n",
            "model_육아/교육\n",
            "[('어짜피/MAG', 0.38448911905288696), ('돌려받/VV', 0.4091818034648895), ('되묻/VV', 0.5073885321617126), ('쳐다보/VV', 0.4607657194137573), ('아직/MAG', 0.39721962809562683), ('지금/MAG', 0.3769499659538269), ('말리/VV', 0.4103665351867676), ('차/VA', 0.4055939316749573), ('모조리/MAG', 0.46439850330352783), ('급히/MAG', 0.5128207206726074)]\n",
            "426\n",
            "model_정치개혁\n",
            "[('울부짖/VV', 0.4520302712917328), ('옥죄/VV', 0.3116099238395691), ('돌려보내/VV', 0.3528742790222168), ('지금/MAG', 0.4398104250431061), ('말리/VV', 0.32713133096694946), ('차/VA', 0.3060814142227173), ('손놓/VV', 0.34131309390068054), ('뚫/VV', 0.3119423985481262), ('줄어드/VV', 0.4045274555683136), ('싸/VV', 0.332097589969635)]\n",
            "556\n",
            "model_인권/성평등\n",
            "[('각자/MAG', 0.3714860677719116), ('월등히/MAG', 0.3808846175670624), ('어짜피/MAG', 0.3398669362068176), ('천천히/MAG', 0.35631269216537476), ('울부짖/VV', 0.5297276973724365), ('쳐다보/VV', 0.3803969919681549), ('발맞추/VV', 0.4362397789955139), ('돌려보내/VV', 0.37996387481689453), ('지금/MAG', 0.3232644498348236), ('말리/VV', 0.33548182249069214)]\n",
            "497\n",
            "model_문화/예술/체육/언론\n",
            "[('외치/VV', 0.4823158085346222), ('돌려받/VV', 0.67865389585495), ('추/VV', 0.490033894777298), ('쳐다보/VV', 0.6471350193023682), ('갈아엎/VV', 0.566965639591217), ('거듭/MAG', 0.4927414357662201), ('지금/MAG', 0.47754931449890137), ('맘껏/MAG', 0.5151338577270508), ('모조리/MAG', 0.4621913433074951), ('대가/VV', 0.6479518413543701)]\n",
            "372\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}